{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PISA Analysis: Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from sas7bdat import SAS7BDAT\n",
    "path = r\"D:\\Data Science Folder\\PISA Analysis\\Data\\2018\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the data to CSV\n",
    "While Pandas can read the data, it was not possible to read it into memory. I use the package SAS7BDAT to export the files to CSV. They can afterwards be read as CSV normally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory D:\\BigQueryDatabase\\PISA\\2018  already exists\n"
     ]
    }
   ],
   "source": [
    "ReadPath = r\"D:\\Data Science Folder\\PISA Analysis\\Data\" \n",
    "Folder = [\"01 - Student Questionnaire\", \n",
    "          \"02 - Cognitive Item\", \n",
    "          \"03 - Teacher Questionnaire\", \n",
    "          \"04 - School Questionnaire\", \n",
    "          \"05 - Questionnaire Timing\"]\n",
    "FileName = [\"cy07_msu_stu_qqq.sas7bdat\", \n",
    "            \"cy07_msu_stu_cog.sas7bdat\", \n",
    "            \"cy07_msu_tch_qqq.sas7bdat\", \n",
    "            \"cy07_msu_sch_qqq.sas7bdat\", \n",
    "            \"cy07_msu_stu_tim.sas7bdat\"]\n",
    "\n",
    "DataYear = 2018\n",
    "WritePath = r\"D:\\BigQueryDatabase\\PISA\" \n",
    "WritePath = os.path.join(WritePath,str(DataYear))\n",
    "if not os.path.exists(WritePath):\n",
    "    os.makedirs(WritePath)\n",
    "    print('Created directory:', WritePath)\n",
    "else:\n",
    "    print('Directory', WritePath, 'already exists')\n",
    "\n",
    "for i in range(0,len(FileName)):\n",
    "    # read the file\n",
    "    readpath = os.path.join(ReadPath,Folder[i],FileName[i])\n",
    "    reader = SAS7BDAT(readpath)\n",
    "    \n",
    "    # convert to csv\n",
    "    writepath = os.path.join(WritePath,FileName[i].replace('sas7bdat','csv'))\n",
    "    reader.convert_file(writepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing the data\n",
    "The data is available at the official PISA website (link here) in two formats: SAS, and SPSS. I proceed with the SPSS data since it requires reading only one file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Codebook \n",
    "The first important file to download is the codebook. PISA data is collected in questionnaires, each item of which is codified. Both the variable name (column) and the values (entries) may need to be joined with the codebook to get their labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_codebook(path = r\"D:\\Data Science Folder\\PISA Analysis\\Data\\2018\\PISA2018_CODEBOOK.xlsx\"): \n",
    "    \"\"\" \n",
    "    Description: This function reads the codebook for PISA 2018. It may work for older versions of PISA assuming they follow the same format\n",
    "    \n",
    "    Inputs: \n",
    "        - path: the location where to find the codebook file in excel format.\n",
    "    Outputs: \n",
    "        - Codebook: A DataFrame containing codes and labels of the variables and values\n",
    "    \"\"\"\n",
    "    Sheets = pd.ExcelFile(path).sheet_names\n",
    "    Codebook = pd.DataFrame()\n",
    "    \n",
    "    for sheet in Sheets:\n",
    "        df = pd.read_excel(path, sheet_name = sheet)\n",
    "        df.loc[:,'DataFile'] = sheet\n",
    "        df = df.reset_index(drop = True)\n",
    "\n",
    "        DataFrame = df[['VAL','LABEL']].dropna().reset_index()\n",
    "        DataFrame.columns = ['index','Value', 'Val_Label']\n",
    "\n",
    "        temp = df[['NAME', 'VARLABEL', 'DataFile']].dropna().reset_index()\n",
    "        temp.loc[:,'repeats'] = (temp['index'].shift(-1)- temp['index']).fillna(max(temp['index']) - max(DataFrame['index']))\n",
    "        DataFrame['Variable'] = temp['NAME'].repeat(temp['repeats']).reset_index(drop = True)\n",
    "        DataFrame['Var_Label'] = temp['VARLABEL'].repeat(temp['repeats']).reset_index(drop = True)\n",
    "        DataFrame['DataFile'] = temp['DataFile'].repeat(temp['repeats']).reset_index(drop = True)\n",
    "\n",
    "        DataFrame = DataFrame.drop('index', axis =1)\n",
    "        Codebook = Codebook.append(DataFrame)\n",
    "\n",
    "    \n",
    "    return Codebook\n",
    "\n",
    "def get_varlabels(DataFrame, VarLabels):\n",
    "    \"\"\"\n",
    "    Description: This function takes a dataframe and passes it through the codebook to get the variable labels. \n",
    "    \n",
    "    Inputs: \n",
    "        - DataFrame: A pandas DataFrame containing the data for which the variable labels are needed\n",
    "        - VarLabels: A pandas DataFrame containing the Codebook read variable labels. \n",
    "    \"\"\"\n",
    "    # Getting the variable labels\n",
    "\n",
    "    left = VarLabels[VarLabels.ITEM == filename.replace('.sav','')][['NAME', 'VARLABEL']]\n",
    "    right = pd.DataFrame({'NAME':DataFrame.columns})\n",
    "    NewCols = pd.merge(left,right,how = 'inner')\n",
    "\n",
    "    # Replacing the variable labels \n",
    "    DataFrame = DataFrame.loc[:,NewCols.NAME]\n",
    "    DataFrame.columns = NewCols.VARLABEL\n",
    "    \n",
    "    return DataFrame\n",
    "\n",
    "def ReadSASDataFile(\n",
    "    filepath = r\"D:\\Data Science Folder\\PISA Analysis\\2018_Cognitive_Item_Data_Files\\cy07_msu_stu_cog.sas7bdat\",\n",
    "    chunksize = 50000, \n",
    "    outpath = 'Exported',\n",
    "    encoding = \"Latin1\"):\n",
    "    \n",
    "    import os\n",
    "    import pandas as pd\n",
    "    print(\"Filepath:\", filepath)\n",
    "    chunks = pd.read_sas(filepath,\n",
    "                         encoding = encoding,\n",
    "                         chunksize = 50000)\n",
    "    basename = os.path.basename(filepath).split('.')[0]\n",
    "    outpath =  filepath.replace(os.path.basename(filepath),outpath)\n",
    "    if not os.path.exists(outpath):\n",
    "        os.mkdir(outpath)\n",
    "    \n",
    "\n",
    "    CountryCodes = pd.Series()\n",
    "    iteration = 0 \n",
    "    for chunk in chunks: \n",
    "        CountryCodes = chunk.CNTRYID.drop_duplicates().reset_index(drop=True).astype(int).astype(str)\n",
    "        iteration = iteration +1\n",
    "        print(\"Working with chunk \", iteration)\n",
    "        run = 0 \n",
    "        for Country in CountryCodes:\n",
    "            run = run + 1\n",
    "            print(\"Working with Country \", run, \" out of \", len(CountryCodes))\n",
    "            filename = basename + \"_\" + Country +'.csv'\n",
    "            filename = os.path.join(outpath,filename)\n",
    "            try:\n",
    "                df = pd.read_csv(filename, index_col = False)\n",
    "            except:\n",
    "                df = pd.DataFrame()\n",
    "                (df.append(chunk[chunk.CNTRYID.astype(int).astype(str) == Country])\n",
    "                 .to_csv(filename, \n",
    "                     index = False)\n",
    "                )\n",
    "            print(\"Completed all countries for this chunk. Moving to the next one.\")\n",
    "    print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"PISA2018_CODEBOOK.xlsx\"\n",
    "Codebook = read_codebook(os.path.join(path,filename))\n",
    "Codebook.to_excel(r'.\\Processed Data\\Codebook.xlsx', index = False)\n",
    "Codebook.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_directory = \"01 - Student Questionnaire\"\n",
    "filename = \"CY07_MSU_STU_QQQ.sav\"\n",
    "StuData = pd.read_spss(os.path.join(path, file_directory,filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
