{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PISA Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from sas7bdat import SAS7BDAT\n",
    "path = r\"D:\\Data Science Folder\\PISA Analysis\\Data\\2018\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the data to CSV\n",
    "While Pandas can read the data, it was not possible to read it into memory. I use the package SAS7BDAT to export the files to CSV. They can afterwards be read as CSV normally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAS7BDAT file: cy07_msu_stu_qqq.sas7bdat\n",
      "SAS7BDAT file: cy07_msu_stu_cog.sas7bdat\n",
      "SAS7BDAT file: cy07_msu_tch_qqq.sas7bdat\n",
      "SAS7BDAT file: cy07_msu_sch_qqq.sas7bdat\n",
      "SAS7BDAT file: cy07_msu_stu_tim.sas7bdat\n"
     ]
    }
   ],
   "source": [
    "BasePath = r\"D:\\Data Science Folder\\PISA Analysis\\Data\\2018\" \n",
    "FilePath = [\"01 - Student Questionnaire\", \n",
    "            \"02 - Cognitive Item\", \n",
    "            \"03 - Teacher Questionnaire\", \n",
    "            \"04 - School Questionnaire\", \n",
    "            \"05 - Questionnaire Timing\"]\n",
    "FileName = [\"cy07_msu_stu_qqq.sas7bdat\", \n",
    "            \"cy07_msu_stu_cog.sas7bdat\", \n",
    "            \"cy07_msu_tch_qqq.sas7bdat\", \n",
    "            \"cy07_msu_sch_qqq.sas7bdat\", \n",
    "            \"cy07_msu_stu_tim.sas7bdat\"\n",
    "           ]\n",
    "for i in range(0,len(FileName)):\n",
    "    path = os.path.join(BasePath,FilePath[i],FileName[i])\n",
    "    writepath = readpath.replace('sas7bdat','csv')\n",
    "    reader = SAS7BDAT(path)\n",
    "    filename = FileName[i].replace('sas7bdat','csv')\n",
    "    path = os.path.join(BasePath,FilePath[i],filename)\n",
    "    reader.convert_file(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing the data\n",
    "The data is available at the official PISA website (link here) in two formats: SAS, and SPSS. I proceed with the SPSS data since it requires reading only one file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Codebook \n",
    "The first important file to download is the codebook. PISA data is collected in questionnaires, each item of which is codified. Both the variable name (column) and the values (entries) may need to be joined with the codebook to get their labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_codebook(path = r\"D:\\Data Science Folder\\PISA Analysis\\Data\\2018\\PISA2018_CODEBOOK.xlsx\"): \n",
    "    \"\"\" \n",
    "    Description: This function reads the codebook for PISA 2018. It may work for older versions of PISA assuming they follow the same format\n",
    "    \n",
    "    Inputs: \n",
    "        - path: the location where to find the codebook file in excel format.\n",
    "    Outputs: \n",
    "        - Codebook: A DataFrame containing codes and labels of the variables and values\n",
    "    \"\"\"\n",
    "    Sheets = pd.ExcelFile(path).sheet_names\n",
    "    Codebook = pd.DataFrame()\n",
    "    \n",
    "    for sheet in Sheets:\n",
    "        df = pd.read_excel(path, sheet_name = sheet)\n",
    "        df.loc[:,'DataFile'] = sheet\n",
    "        df = df.reset_index(drop = True)\n",
    "\n",
    "        DataFrame = df[['VAL','LABEL']].dropna().reset_index()\n",
    "        DataFrame.columns = ['index','Value', 'Val_Label']\n",
    "\n",
    "        temp = df[['NAME', 'VARLABEL', 'DataFile']].dropna().reset_index()\n",
    "        temp.loc[:,'repeats'] = (temp['index'].shift(-1)- temp['index']).fillna(max(temp['index']) - max(DataFrame['index']))\n",
    "        DataFrame['Variable'] = temp['NAME'].repeat(temp['repeats']).reset_index(drop = True)\n",
    "        DataFrame['Var_Label'] = temp['VARLABEL'].repeat(temp['repeats']).reset_index(drop = True)\n",
    "        DataFrame['DataFile'] = temp['DataFile'].repeat(temp['repeats']).reset_index(drop = True)\n",
    "\n",
    "        DataFrame = DataFrame.drop('index', axis =1)\n",
    "        Codebook = Codebook.append(DataFrame)\n",
    "\n",
    "    \n",
    "    return Codebook\n",
    "\n",
    "def get_varlabels(DataFrame, VarLabels):\n",
    "    \"\"\"\n",
    "    Description: This function takes a dataframe and passes it through the codebook to get the variable labels. \n",
    "    \n",
    "    Inputs: \n",
    "        - DataFrame: A pandas DataFrame containing the data for which the variable labels are needed\n",
    "        - VarLabels: A pandas DataFrame containing the Codebook read variable labels. \n",
    "    \"\"\"\n",
    "    # Getting the variable labels\n",
    "\n",
    "    left = VarLabels[VarLabels.ITEM == filename.replace('.sav','')][['NAME', 'VARLABEL']]\n",
    "    right = pd.DataFrame({'NAME':DataFrame.columns})\n",
    "    NewCols = pd.merge(left,right,how = 'inner')\n",
    "\n",
    "    # Replacing the variable labels \n",
    "    DataFrame = DataFrame.loc[:,NewCols.NAME]\n",
    "    DataFrame.columns = NewCols.VARLABEL\n",
    "    \n",
    "    return DataFrame\n",
    "\n",
    "def ReadSASDataFile(\n",
    "    filepath = r\"D:\\Data Science Folder\\PISA Analysis\\2018_Cognitive_Item_Data_Files\\cy07_msu_stu_cog.sas7bdat\",\n",
    "    chunksize = 50000, \n",
    "    outpath = 'Exported',\n",
    "    encoding = \"Latin1\"):\n",
    "    \n",
    "    import os\n",
    "    import pandas as pd\n",
    "    print(\"Filepath:\", filepath)\n",
    "    chunks = pd.read_sas(filepath,\n",
    "                         encoding = encoding,\n",
    "                         chunksize = 50000)\n",
    "    basename = os.path.basename(filepath).split('.')[0]\n",
    "    outpath =  filepath.replace(os.path.basename(filepath),outpath)\n",
    "    if not os.path.exists(outpath):\n",
    "        os.mkdir(outpath)\n",
    "    \n",
    "\n",
    "    CountryCodes = pd.Series()\n",
    "    iteration = 0 \n",
    "    for chunk in chunks: \n",
    "        CountryCodes = chunk.CNTRYID.drop_duplicates().reset_index(drop=True).astype(int).astype(str)\n",
    "        iteration = iteration +1\n",
    "        print(\"Working with chunk \", iteration)\n",
    "        run = 0 \n",
    "        for Country in CountryCodes:\n",
    "            run = run + 1\n",
    "            print(\"Working with Country \", run, \" out of \", len(CountryCodes))\n",
    "            filename = basename + \"_\" + Country +'.csv'\n",
    "            filename = os.path.join(outpath,filename)\n",
    "            try:\n",
    "                df = pd.read_csv(filename, index_col = False)\n",
    "            except:\n",
    "                df = pd.DataFrame()\n",
    "                (df.append(chunk[chunk.CNTRYID.astype(int).astype(str) == Country])\n",
    "                 .to_csv(filename, \n",
    "                     index = False)\n",
    "                )\n",
    "            print(\"Completed all countries for this chunk. Moving to the next one.\")\n",
    "    print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"PISA2018_CODEBOOK.xlsx\"\n",
    "Codebook = read_codebook(os.path.join(path,filename))\n",
    "Codebook.to_excel(r'.\\Processed Data\\Codebook.xlsx', index = False)\n",
    "Codebook.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReadSASDataFile(filepath = r'D:\\Data Science Folder\\PISA Analysis\\Data\\2018\\05 - Questionnaire Timing\\cy07_msu_stu_tim.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReadSASDataFile(filepath = r'D:\\Data Science Folder\\PISA Analysis\\Data\\2018\\03 - Teacher Questionnaire\\cy07_msu_tch_qqq.sas7bdat', \n",
    "               encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Codebook[(Codebook.Variable == \"CNTRYID\")&(Codebook.DataFile == \"CY07_MSU_TCH_QQQ\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Codebook[(Codebook.Variable == \"CNTRYID\")&(Codebook.DataFile == \"CY07_MSU_TCH_QQQ\")].Val_Label.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Questionnaire Data\n",
    "The PISA data is composed of four questionnaires: \n",
    " 1. The Student Questionnaire: Students were asked to evaluate their knowledge and ability. This is just as much a measure of a student relative to their peers, as is of a teacher, a school, and a country relative to others. \n",
    " 2. The Student Cognitive Questionnaire: Students were also asked to complete a cognitive test. \n",
    " 3. The Teacher Questionnaire: Teachers were asked questions with the intent of describing the immediate environment where students are learning. \n",
    " 4. The School Questionnaire: School principals were also asked to describe the state of the school with the goal of measuring their ability to create an environment that foster learning. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Student Questionnaire: \n",
    "This data file is quite big (1.8 GB). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_directory = \"01 - Student Questionnaire\"\n",
    "filename = \"CY07_MSU_STU_QQQ.sav\"\n",
    "StuData = pd.read_spss(os.path.join(path, file_directory,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Cognitive Student Questionnaire: \n",
    "This data file is even bgiger (2.8 GB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_directory = \"02 - Cognitive Item\"\n",
    "filename = \"CY07_MSU_STU_COG.sav\"\n",
    "CogData = pd.read_spss(os.path.join(path, file_directory,filename), convert_categoricals = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Teacher Questionnaire: \n",
    "This data file is not very big (57 MB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_directory = \"03 - Teacher Questionnaire\"\n",
    "filename = \"CY07_MSU_TCH_QQQ.sav\"\n",
    "TchData = pd.read_spss(os.path.join(path, file_directory,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The School Questionnaire: \n",
    "\n",
    "This data file is small (10 MB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the file\n",
    "file_directory = \"04 - SChool Questionnaire\"\n",
    "filename = \"CY07_MSU_SCH_QQQ.sav\"\n",
    "SchData = pd.read_spss(os.path.join(path, file_directory,filename))\n",
    "\n",
    "SchData = get_varlabels(SchData, VarLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SchData.columns.to_frame()[100:220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SchData[SchData['Country Identifier'] == 'Dominican Republic'][['Intl. School ID']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(SchData\n",
    " [SchData['Country Identifier'] == 'Dominican Republic']\n",
    " [[\"Which of the following definitions best describes the community in which your school is located?\"]]\n",
    " .drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(SchData\n",
    " [SchData['Country Identifier'] == 'Dominican Republic']\n",
    " .groupby(\"Which of the following definitions best describes the community in which your school is located?\")\n",
    " [['Intl. School ID']]\n",
    " .agg('nunique')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(SchData\n",
    " [SchData['Country Identifier'] == 'Dominican Republic']\n",
    " .groupby(\"Is your school a public or a private school?\")\n",
    " [['Intl. School ID']]\n",
    " .agg('nunique')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(SchData\n",
    " [(SchData['Country Identifier'] == 'Dominican Republic')\n",
    "  &\n",
    "  (SchData['Is your school a public or a private school?'].str.contains('private'))]\n",
    " .iloc[:,SchData.columns.str.startswith('Percentage of total funding')]\n",
    " .agg('mean')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(SchData\n",
    " [(SchData['Country Identifier'] == 'Dominican Republic')\n",
    "  &\n",
    "  (SchData['Is your school a public or a private school?'].str.contains('public'))]\n",
    " .iloc[:,SchData.columns.str.startswith(\"School's use of assessments of students:\")]\n",
    " .melt()\n",
    " .reset_index()\n",
    " .groupby(['VARLABEL', 'value'])\n",
    " .agg('count')\n",
    " .reset_index()\n",
    " .pivot('VARLABEL','value','index')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadstat as spss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_directory = \"02 - Cognitive Item\"\n",
    "filename = \"CY07_MSU_STU_COG.sav\"\n",
    "CogData = spss.read_sav(os.path.join(path, file_directory,filename), row_limit = 100)[0]\n",
    "CogData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"D:\\Data Science Folder\\PISA Analysis\\2018_Cognitive_Item_Data_Files\\cy07_msu_stu_cog.sas7bdat\"\n",
    "import os\n",
    "filename = os.path.basename(filepath).split('.')[0]\n",
    "\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    chunks = pd.read_sas(filepath,\n",
    "                         encoding = 'Latin1',\n",
    "                         chunksize = 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReadSASDataFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
